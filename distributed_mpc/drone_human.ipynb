{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from casadi import *\n",
    "import casadi as cs\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from util import *\n",
    "import itertools \n",
    "from time import perf_counter\n",
    "import sympy as sym\n",
    "from IPython.display import display, Math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decentralized import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An example of using Casadi to optimize trajectory for a Human (modelled with a unicycle):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Δt = sym.Symbol('\\Delta t')\n",
    "sθ = sym.Symbol('\\sin \\Theta')\n",
    "cθ = sym.Symbol('\\cos \\Theta')\n",
    "p_x, p_y, p_z, v, omega, theta, a = sym.symbols('p_x p_y p_z v omega theta a')\n",
    "\n",
    "x = sym.Matrix([p_x, p_y, p_z, v])\n",
    "u = sym.Matrix([theta, a])\n",
    "display(Math('x = ' + sym.latex(x) + '\\;u = ' + sym.latex(u)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([0, 0, 1.7, 0.05, 0, 0])\n",
    "xf = np.array([1.5,1.5,1.7,0, 0, 0])\n",
    "\n",
    "Q = np.eye(6)*5\n",
    "R = np.eye(3)*0.1\n",
    "Qf = np.eye(6)*100\n",
    "\n",
    "u_ref = np.array([0,0,0])\n",
    "\n",
    "N = 100\n",
    "\n",
    "opti = Opti()\n",
    "\n",
    "dt = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = opti.variable(6,N+1)\n",
    "U = opti.variable(3,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x,u: vertcat(x[3]*cos(u[0]),x[3]*sin(u[0]),0,u[1], 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(N): #loop over control intervals\n",
    "    # Runge-Kutta 4 integration\n",
    "    k1 = f(X[:,k],         U[:,k])\n",
    "    k2 = f(X[:,k]+dt/2*k1, U[:,k])\n",
    "    k3 = f(X[:,k]+dt/2*k2, U[:,k])\n",
    "    k4 = f(X[:,k]+dt*k3,   U[:,k])\n",
    "    x_next = X[:,k] + dt/6*(k1+2*k2+2*k3+k4) \n",
    "\n",
    "    opti.subject_to(X[:,k+1]==x_next) # close the gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_stage_cost = 0\n",
    "for j in range(X.shape[1]-1):\n",
    "    for i in range(X.shape[0]):\n",
    "        total_stage_cost += (X[i,j]-xf[i])*Q[i, i]*(X[i,j]-xf[i])\n",
    "\n",
    "for j in range(U.shape[1]-1):\n",
    "    for i in range(U.shape[0]):\n",
    "        total_stage_cost += (U[i,j]-u_ref[i])*R[i, i]*(U[i,j]-u_ref[i])\n",
    "\n",
    "#Quadratic terminal cost:\n",
    "total_terminal_cost = 0\n",
    "# for j in range(X.shape[1]):\n",
    "for i in range(X.shape[0]):\n",
    "    total_terminal_cost += (X[i,-1]-xf[i])*Qf[i, i]*(X[i,-1]-xf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective = total_terminal_cost + total_stage_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti.minimize(objective) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti.subject_to(X[0,:]<=3) # p_x is limited\n",
    "opti.subject_to(-3<=X[0,:])\n",
    "\n",
    "opti.subject_to(X[1,:]<=3) # p_y is limited\n",
    "opti.subject_to(-3<=X[1,:])\n",
    "\n",
    "opti.subject_to(X[3,:]<=5) # v is limited\n",
    "opti.subject_to(-5<=X[3,:])\n",
    "\n",
    "opti.subject_to(U[0,:]<=np.pi/2) # theta is limited\n",
    "opti.subject_to(-np.pi/2<=U[0,:])\n",
    "\n",
    "opti.subject_to(U[1,:]<=1) # a is limited\n",
    "opti.subject_to(-1<=U[1,:]) \n",
    "\n",
    "#equality constraints:\n",
    "opti.subject_to(X[:,0] == x0)\n",
    "t0 = perf_counter()\n",
    "opti.solver('ipopt');\n",
    "sol = opti.solve()\n",
    "tf = perf_counter()\n",
    "\n",
    "print(f'total run time is {tf-t0} seconds')\n",
    "X_trj = sol.value(X)\n",
    "U_trj = sol.value(U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter(X_trj[0,:],X_trj[1,:],X_trj[2,:])\n",
    "ax.set_title('Trajectory from one-shot optimization (human)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running inhomogenous test with 2 quadrotors and 1 human (receding-horizon):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(X,U,u_ref,xf,Q,R,Qf):\n",
    "    total_stage_cost = 0\n",
    "    for j in range(X.shape[1]-1):\n",
    "        for i in range(X.shape[0]):\n",
    "            total_stage_cost += (X[i,j]-xf[i])*Q[i, i]*(X[i,j]-xf[i])\n",
    "\n",
    "    for j in range(U.shape[1]-1):\n",
    "        for i in range(U.shape[0]):\n",
    "            total_stage_cost += (U[i,j]-u_ref[i])*R[i, i]*(U[i,j]-u_ref[i])\n",
    "\n",
    "    #Quadratic terminal cost:\n",
    "    total_terminal_cost = 0\n",
    "\n",
    "    for i in range(X.shape[0]):\n",
    "        total_terminal_cost += (X[i,-1]-xf[i])*Qf[i, i]*(X[i,-1]-xf[i])\n",
    "            \n",
    "    return total_stage_cost + total_terminal_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_f_human_drone(x_dims_local,n_human):\n",
    "    g = 9.8\n",
    "    # NOTE: Assume homogeneity of agents.\n",
    "    n_agents = len(x_dims_local)\n",
    "    n_states = x_dims_local[0]\n",
    "    n_controls = 3\n",
    "    \n",
    "    def f(x, u):\n",
    "        x_dot = cs.MX.zeros(x.numel())\n",
    "        for i_agent in range(0,n_agents-n_human):\n",
    "            i_xstart = i_agent * n_states\n",
    "            i_ustart = i_agent * n_controls\n",
    "            x_dot[i_xstart:i_xstart + n_states] = cs.vertcat(\n",
    "                x[i_xstart + 3: i_xstart + 6],\n",
    "                g*cs.tan(u[i_ustart]), -g*cs.tan(u[i_ustart+1]), u[i_ustart+2] - g\n",
    "                )\n",
    "        # count = 0\n",
    "        for j_agent in range(n_agents-n_human,n_agents):\n",
    "            j_xstart = j_agent * n_states\n",
    "            j_ustart = j_agent * n_controls #human agent has 2 control var.\n",
    "            # if count > 0:\n",
    "            #     j_ustart -=1\n",
    "            # count +=1\n",
    "            \n",
    "            x_dot[j_xstart:j_xstart + n_states] = cs.vertcat(\n",
    "                x[j_xstart + 3]*cs.cos(u[j_ustart]), x[j_xstart+3]*cs.sin(u[j_ustart]),0,\n",
    "                u[j_ustart+1], 0 , 0\n",
    "                )\n",
    "            \n",
    "        return x_dot\n",
    "    \n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 drones + 1 human:\n",
    "n_agents = 3\n",
    "n_humans = 1\n",
    "n_states = 6\n",
    "n_inputs = 3\n",
    "n_dims = [3,3,2]\n",
    "x_dims = [6,6,6]\n",
    "u_dims = [3,3,3]\n",
    "\n",
    "x0 = np.array([[0.5, 1.5, 1.5, 0, 0, 0,   #Drone\n",
    "               2.5, 1.5, 1.5, 0, 0, 0,   #Drone\n",
    "               1, 1, 1.7, 0.01, 0, 0]]).T #Human \n",
    "\n",
    "xf = np.array([[ 2.5, 1.5, 1.5, 0, 0, 0, \n",
    "                0.5, 1.5, 1.5, 0, 0, 0,\n",
    "                2, 2, 1.7, 0,  0,  0]]).T\n",
    "\n",
    "Q = np.eye(n_agents*n_states)*10\n",
    "R = np.eye(sum(u_dims))*0.1\n",
    "Qf = np.eye(n_agents*n_states)*100\n",
    "g = 9.81\n",
    "u_ref = np.array([0,0,g,0,0,g,0,0,0])\n",
    "\n",
    "dt = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# f = lambda x,u: vertcat(x[3],x[4],x[5],g*tan(u[0]),-g*tan(u[1]),u[2]-g,\n",
    "#                     x[9],x[10],x[11], g*tan(u[3]), -g*tan(u[4]),u[5]-g,\n",
    "#                     x[15]*cos(u[6]), x[15]*sin(u[6]), 0, u[7], 0, 0)\n",
    "f = generate_f_human_drone(x_dims,n_humans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_max = np.pi / 6\n",
    "phi_max = np.pi / 6\n",
    "\n",
    "v_max = 3\n",
    "v_min = -3\n",
    "\n",
    "theta_min = -np.pi / 6\n",
    "phi_min = -np.pi / 6\n",
    "\n",
    "tau_max = 15\n",
    "tau_min = 0\n",
    "\n",
    "x_min = -5\n",
    "x_max = 5\n",
    "\n",
    "y_min = -5\n",
    "y_max = 5\n",
    "\n",
    "z_min = 0\n",
    "z_max = 3.5\n",
    "\n",
    "max_input_base = np.array([[theta_max], [phi_max], [tau_max]])\n",
    "min_input_base = np.array([[theta_min], [phi_min], [tau_min]])\n",
    "max_state_base = np.array([[x_max], [y_max], [z_max], [v_max],[v_max], [v_max]])\n",
    "min_state_base = np.array([[x_min], [y_min], [z_min], [v_min],[v_min], [v_min]])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# max_input_human = np.array([np.pi/2,2])\n",
    "# min_input_human = np.array([-np.pi/2,-2])\n",
    "\n",
    "# max_state_human = np.array([x_max,y_max,z_max,v_max,0,0])\n",
    "# min_state_human = np.array([x_min,y_min,z_min,v_min,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#actually it makes no sense to put constraints on the human agent; \n",
    "#human agent is assumed to be irrational"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius = 0.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up constraints for the drones:\n",
    "max_input = np.tile(max_input_base,(n_agents-n_humans,1))\n",
    "min_input = np.tile(min_input_base,(n_agents-n_humans,1))\n",
    "max_state = np.tile(max_state_base,(n_agents-n_humans,1))\n",
    "min_state = np.tile(min_state_base,(n_agents-n_humans,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_rhc(x0,xf,u_ref,N,Q,R,Qf,n_agents,n_states,d_threshold,n_dims,u_dims):\n",
    "    #N is the shifting prediction horizon\n",
    "    \n",
    "    p_opts = {\"expand\":True}\n",
    "    s_opts = {\"max_iter\": 1000,\"print_level\":0}\n",
    "    \n",
    "    \n",
    "    M = 200 # this is the entire fixed horizon\n",
    " \n",
    "    n_x = n_agents*n_states\n",
    "    # n_u = n_agents*n_inputs\n",
    "    n_u = sum(u_dims)\n",
    "    x_dims = [n_states]*n_agents\n",
    "    \n",
    "    X_full = np.zeros((0, n_x))\n",
    "    U_full = np.zeros((0, n_u))\n",
    "    \n",
    "    t = 0\n",
    "\n",
    "    J_list = []\n",
    "    J_list.append(np.inf)\n",
    "    # for i in range(M) :\n",
    "    i = 0\n",
    "    dt = 0.1\n",
    "    \n",
    "    while np.any(distance_to_goal(x0,xf,n_agents,n_states) > 0.1)  and (i < M):\n",
    "        \n",
    "        \n",
    "        opti = Opti()\n",
    "        \n",
    "        X = opti.variable(n_x,N+1)\n",
    "        U = opti.variable(n_u,N)\n",
    "        \n",
    "        cost_fun = objective(X,U,u_ref,xf,Q,R,Qf)\n",
    "        opti.minimize(cost_fun)\n",
    "\n",
    "        for k in range(N): #loop over control intervals\n",
    "            # Runge-Kutta 4 integration\n",
    "            k1 = f(X[:,k],         U[:,k])\n",
    "            k2 = f(X[:,k]+dt/2*k1, U[:,k])\n",
    "            k3 = f(X[:,k]+dt/2*k2, U[:,k])\n",
    "            k4 = f(X[:,k]+dt*k3,   U[:,k])\n",
    "            x_next = X[:,k] + dt/6*(k1+2*k2+2*k3+k4) \n",
    "\n",
    "            opti.subject_to(X[:,k+1]==x_next) # close the gaps\n",
    "    \n",
    "            opti.subject_to(U[0:(n_agents-n_humans)*n_inputs,k] <= max_input)\n",
    "            opti.subject_to(min_input <= U[0:(n_agents-n_humans)*n_inputs,k])\n",
    "   \n",
    "        #collision avoidance constraints\n",
    "        for k in range(N+1):\n",
    "            distances = compute_pairwise_distance_nd_Sym(X[:,k], x_dims,n_dims)\n",
    "            opti.subject_to(X[0:(n_agents-n_humans)*n_states,k] <= max_state)\n",
    "            opti.subject_to(min_state <= X[0:(n_agents-n_humans)*n_states,k])\n",
    "\n",
    "            for n in range(len(distances)):\n",
    "                opti.subject_to(distances[n] >= radius)\n",
    "    \n",
    "        #equality constraints for initial condition:\n",
    "        opti.subject_to(X[:,0] == x0)\n",
    "        \n",
    "        opti.solver(\"ipopt\",p_opts,\n",
    "                    s_opts) \n",
    "        \n",
    "        sol = opti.solve()\n",
    "        # print(opti.debug.value)\n",
    "        x0 = sol.value(X)[:,1].reshape(-1,1)\n",
    "        # print(x0.shape)\n",
    "        u_sol = sol.value(U)[:,0]\n",
    "        \n",
    "        J_list.append(sol.value(cost_fun))\n",
    "        print(f'current objective function value is {sol.value(cost_fun)}')\n",
    "        \n",
    "        \n",
    "        #Store the trajectory\n",
    "        \n",
    "        X_full = np.r_[X_full, x0.reshape(1,-1)]\n",
    "        U_full = np.r_[U_full, u_sol.reshape(1,-1)]\n",
    "        \n",
    "        t += dt\n",
    "        i +=1\n",
    "        \n",
    "        # print(opti.variable) #print this to check the optimization parameters for each control horizon\n",
    "        \n",
    "        if abs(J_list[i]-J_list[i-1]) <= 1.0 :\n",
    "            print(f'Terminated! at i = {i}')\n",
    "            break\n",
    "            \n",
    "        \n",
    "    return X_full,U_full, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#equality constraints:\n",
    "N = 10\n",
    "t0 = perf_counter()\n",
    "n_agents = 3\n",
    "n_states = 6\n",
    "X_trj,u_trj, t = solve_rhc(x0,xf,u_ref,N,Q,R,Qf,n_agents,n_states,radius,n_dims,u_dims)\n",
    "tf = perf_counter()\n",
    "print(f'total run time is {tf-t0} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "plt.figure(dpi=150)\n",
    "util.plot_solve(X_trj,10,xf,x_dims,True,3)\n",
    "ax = plt.gca()\n",
    "ax.legend(plt.gca().get_children()[1:3], [\"Start Position\", \"Goal Position\"])\n",
    "plt.title('Centralized RHC (IPOPT) (1 human & 2 drones)')\n",
    "plt.savefig('results/one_human_2_drones(centralized RHC).png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#animate the plot:\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "\n",
    "# first, fill X_trj with some test data\n",
    "\n",
    "\n",
    "# second, create a function that updates the scatter plot for each frame\n",
    "def update_plot(k, X_trj, scatters):\n",
    "     # Set the data for each scatter plot\n",
    "    scatters[0]._offsets3d = X_trj.T[0:3, :k]\n",
    "    scatters[1]._offsets3d = X_trj.T[6:9, :k]\n",
    "    scatters[2]._offsets3d = X_trj.T[12:15, :k]\n",
    "    return scatters\n",
    "\n",
    "# Create the figure and axis\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "# Create the scatter plots\n",
    "scatters = []\n",
    "scatters.append(ax.scatter([], [], []))\n",
    "scatters.append(ax.scatter([], [], []))\n",
    "scatters.append(ax.scatter([], [], []))\n",
    "\n",
    "# set the axis limits\n",
    "ax.set_xlim3d(X_trj.T[[0, 6, 12], :].min(), X_trj.T[[0, 6, 12], :].max())\n",
    "ax.set_ylim3d(X_trj.T[[1, 7, 13], :].min(), X_trj.T[[1, 7, 13], :].max())\n",
    "ax.set_zlim3d(X_trj.T[[2, 8, 14], :].min(), X_trj.T[[2, 8, 14], :].max())\n",
    "\n",
    "\n",
    "# Set the title\n",
    "ax.set_title('Trajectory from one-shot optimization (human + drones)')\n",
    "\n",
    "ani = animation.FuncAnimation(fig, update_plot, frames=100, fargs=(X_trj, scatters))\n",
    "\n",
    "ani.save('animation(1_human_2_drones).mp4')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running inhomogenous test with 3 quadrotors and 2 human (receding-horizon):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_setup_3_quads()[1].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 drones + 2 human:\n",
    "n_agents = 5\n",
    "n_states = 6\n",
    "n_humans = 2\n",
    "n_dims = [3,3,3,2,2]\n",
    "x_dims = [6,6,6,6,6]\n",
    "u_dims = [3,3,3,3,3]\n",
    "\n",
    "x0 = np.array([[0.5, 1.5, 1. , 0. , 0. , 0. ,   #Drone\n",
    "               2.5, 1.5, 1. , 0. , 0. , 0.,   #Drone\n",
    "              1.5, 1.3, 1. , 0. , 0. , 0.,  #Drone\n",
    "              1, 1, 1.7, 0.01, 0, 0 , #Human 1\n",
    "              2.1, 2.1, 1.7, -0.01, 0, 0]]).T # Human 2\n",
    "\n",
    "xf = np.array([[ 2.5, 1.5, 1. , 0. , 0. , 0. , #Drone\n",
    "                0.5, 1.5, 1. , 0. , 0. , 0. , #Drone\n",
    "                1.5, 2.2, 1. , 0. , 0. , 0. , #Drone\n",
    "                2., 2., 1.7, 0,  0,  0,  \n",
    "                1., 1., 1.7, 0,  0,  0]]).T\n",
    "\n",
    "Q = np.eye(n_agents*n_states)*10\n",
    "R = np.eye(sum(u_dims))*0.1\n",
    "Qf = np.eye(n_agents*n_states)*100\n",
    "g = 9.81\n",
    "u_ref = np.array([0,0,g,0,0,g,0,0,g,0,0,0,0,0,0])\n",
    "\n",
    "\n",
    "opti = Opti()\n",
    "\n",
    "dt = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = generate_f_human_drone(x_dims,n_humans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input = np.tile(max_input_base,(n_agents-n_humans,1))\n",
    "min_input = np.tile(min_input_base,(n_agents-n_humans,1))\n",
    "max_state = np.tile(max_state_base,(n_agents-n_humans,1))\n",
    "min_state = np.tile(min_state_base,(n_agents-n_humans,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius = 0.4\n",
    "N = 15\n",
    "t0 = perf_counter()\n",
    "X_trj,u_trj, t = solve_rhc(x0,xf,u_ref,N,Q,R,Qf,n_agents,n_states,radius,n_dims,u_dims)\n",
    "tf = perf_counter()\n",
    "print(f'total run time is {tf-t0} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "plt.figure(dpi=150)\n",
    "util.plot_solve(X_trj,10,xf,x_dims,True,3)\n",
    "ax = plt.gca()\n",
    "ax.legend(plt.gca().get_children()[1:3], [\"Start Position\", \"Goal Position\"])\n",
    "plt.title('Centralized RHC (IPOPT) (2 humans & 3 drones)')\n",
    "plt.savefig('results/two_human_3_drones(Centralized RHC).png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve the problem in distributed fashion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 drones + 1 human:\n",
    "n_agents = 3\n",
    "n_humans = 1\n",
    "n_states = 6\n",
    "n_inputs = 3\n",
    "n_dims = [3,3,2]\n",
    "x_dims = [6,6,6]\n",
    "u_dims = [3,3,3]\n",
    "\n",
    "x0 = np.array([[0.5, 1.5, 1.5, 0, 0, 0,   #Drone\n",
    "               2.5, 1.5, 1.5, 0, 0, 0,   #Drone\n",
    "               1, 1, 1.7, 0.01, 0, 0]]).T #Human \n",
    "\n",
    "xf = np.array([[ 2.5, 1.5, 1.5, 0, 0, 0, \n",
    "                0.5, 1.5, 1.5, 0, 0, 0,\n",
    "                2, 2, 1.7, 0,  0,  0]]).T\n",
    "\n",
    "Q = np.eye(n_agents*n_states)*10\n",
    "R = np.eye(sum(u_dims))*0.1\n",
    "Qf = np.eye(n_agents*n_states)*100\n",
    "g = 9.81\n",
    "u_ref = np.array([0,0,g,0,0,g,0,0,0])\n",
    "\n",
    "dt = 0.1\n",
    "\n",
    "theta_max = np.pi / 6\n",
    "phi_max = np.pi / 6\n",
    "\n",
    "v_max = 3\n",
    "v_min = -3\n",
    "\n",
    "theta_min = -np.pi / 6\n",
    "phi_min = -np.pi / 6\n",
    "\n",
    "tau_max = 15\n",
    "tau_min = 0\n",
    "\n",
    "x_min = -5\n",
    "x_max = 5\n",
    "\n",
    "y_min = -5\n",
    "y_max = 5\n",
    "\n",
    "z_min = 0\n",
    "z_max = 3.5\n",
    "\n",
    "radius = 0.5\n",
    "\n",
    "ids = [100 + i for i in range(n_agents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distributed_mpc import solve_rhc_distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_full, U_full, t, J_list, failed_count, converged = solve_rhc_distributed(\n",
    "    0,x0, xf, u_ref, N, n_agents, n_states, n_inputs, radius, ids,\\\n",
    "    x_min,x_max,y_min,y_max,z_min,z_max,v_min,v_max,theta_max,\\\n",
    "  theta_min,tau_max,tau_min,phi_max,phi_min,n_dims=[3,3,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "plt.figure(dpi=150)\n",
    "util.plot_solve(X_full,10,xf,x_dims,True,3)\n",
    "ax = plt.gca()\n",
    "ax.legend(plt.gca().get_children()[1:3], [\"Start Position\", \"Goal Position\"])\n",
    "plt.title('Distributed RHC (IPOPT) (1 humans & 2 drones)')\n",
    "plt.savefig('results/one_human_2_drones.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 drones + 2 human:\n",
    "n_agents = 5\n",
    "n_states = 6\n",
    "n_humans = 2\n",
    "n_dims = [3,3,3,2,2]\n",
    "x_dims = [6,6,6,6,6]\n",
    "u_dims = [3,3,3,3,3]\n",
    "\n",
    "x0 = np.array([[0.5, 1.5, 1. , 0. , 0. , 0. ,   #Drone\n",
    "               2.5, 1.5, 1. , 0. , 0. , 0.,   #Drone\n",
    "              1.5, 1.3, 1. , 0. , 0. , 0.,  #Drone\n",
    "              1, 1, 1.7, 0.01, 0, 0 , #Human 1\n",
    "              2.1, 2.1, 1.7, -0.01, 0, 0]]).T # Human 2\n",
    "\n",
    "xf = np.array([[ 2.5, 1.5, 1. , 0. , 0. , 0. , #Drone\n",
    "                0.5, 1.5, 1. , 0. , 0. , 0. , #Drone\n",
    "                1.5, 2.2, 1. , 0. , 0. , 0. , #Drone\n",
    "                2., 2., 1.7, 0,  0,  0,  \n",
    "                1., 1., 1.7, 0,  0,  0]]).T\n",
    "\n",
    "Q = np.eye(n_agents*n_states)*10\n",
    "R = np.eye(sum(u_dims))*0.1\n",
    "Qf = np.eye(n_agents*n_states)*100\n",
    "g = 9.81\n",
    "u_ref = np.array([0,0,g,0,0,g,0,0,g,0,0,0,0,0,0])\n",
    "\n",
    "radius = 0.35\n",
    "\n",
    "N = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [100 + i for i in range(n_agents)]\n",
    "X_full, U_full, t, J_list, failed_count, converged = solve_rhc_distributed(\n",
    "    0,x0, xf, u_ref, N, n_agents, n_states, n_inputs, radius, ids,\\\n",
    "    x_min,x_max,y_min,y_max,z_min,z_max,v_min,v_max,theta_max,\\\n",
    "  theta_min,tau_max,tau_min,phi_max,phi_min,n_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "plt.figure(dpi=150)\n",
    "util.plot_solve(X_full,10,xf,x_dims,True,3)\n",
    "ax = plt.gca()\n",
    "ax.legend(plt.gca().get_children()[1:3], [\"Start Position\", \"Goal Position\"])\n",
    "plt.title('Distributed RHC (IPOPT) (2 humans & 3 drones)')\n",
    "plt.savefig('results/two_human_3_drones_distributed.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "47f19a4884d69c1662ba195a765da507abd8104c88696148164f3dd77b63a1cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
